{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38bbac5b-30e1-41cd-a4db-4e36642c26c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from gym) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from gym) (2.2.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: dataclasses==0.8 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from gym) (0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from gym) (4.8.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from importlib-metadata>=4.8.0->gym) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from importlib-metadata>=4.8.0->gym) (4.1.1)\n",
      "Requirement already satisfied: tensorboardX in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (2.5.1)\n",
      "Requirement already satisfied: numpy in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from tensorboardX) (1.19.5)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from tensorboardX) (3.19.4)\n",
      "Collecting urdfenvs\n",
      "  Downloading urdfenvs-0.4.0-py3-none-any.whl (21.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.2 MB 17.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pybullet<4.0.0,>=3.2.1\n",
      "  Downloading pybullet-3.2.5-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (91.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 91.7 MB 258 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.19.0 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from urdfenvs) (1.19.5)\n",
      "Collecting gym<0.22.0,>=0.21.0\n",
      "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 36.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urdfpy<0.0.23,>=0.0.22\n",
      "  Downloading urdfpy-0.0.22-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from gym<0.22.0,>=0.21.0->urdfenvs) (2.2.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.8.1 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from gym<0.22.0,>=0.21.0->urdfenvs) (4.8.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from importlib_metadata>=4.8.1->gym<0.22.0,>=0.21.0->urdfenvs) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from importlib_metadata>=4.8.1->gym<0.22.0,>=0.21.0->urdfenvs) (3.6.0)\n",
      "Requirement already satisfied: six in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from urdfpy<0.0.23,>=0.0.22->urdfenvs) (1.16.0)\n",
      "Requirement already satisfied: pillow in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from urdfpy<0.0.23,>=0.0.22->urdfenvs) (8.4.0)\n",
      "Collecting networkx==2.2\n",
      "  Downloading networkx-2.2.zip (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 61.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from urdfpy<0.0.23,>=0.0.22->urdfenvs) (1.5.4)\n",
      "Collecting pycollada==0.6\n",
      "  Downloading pycollada-0.6.tar.gz (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 81.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyrender>=0.1.20\n",
      "  Downloading pyrender-0.1.45-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 37.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lxml\n",
      "  Downloading lxml-4.9.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 38.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting trimesh\n",
      "  Downloading trimesh-3.16.2-py3-none-any.whl (663 kB)\n",
      "\u001b[K     |████████████████████████████████| 663 kB 87.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from networkx==2.2->urdfpy<0.0.23,>=0.0.22->urdfenvs) (5.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from pycollada==0.6->urdfpy<0.0.23,>=0.0.22->urdfenvs) (2.8.2)\n",
      "Collecting pyglet>=1.4.10\n",
      "  Downloading pyglet-2.0.0-py3-none-any.whl (966 kB)\n",
      "\u001b[K     |████████████████████████████████| 966 kB 63.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyOpenGL==3.1.0\n",
      "  Downloading PyOpenGL-3.1.0.zip (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 68.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio\n",
      "  Downloading imageio-2.15.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 27.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting freetype-py\n",
      "  Downloading freetype_py-2.2.0-py3-none-manylinux1_x86_64.whl (890 kB)\n",
      "\u001b[K     |████████████████████████████████| 890 kB 38.6 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: gym, networkx, pycollada, PyOpenGL\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616826 sha256=b9b8c41b11f110607f7f055bf25f8f6c415011535e0a68dd373b8daea4ddfad9\n",
      "  Stored in directory: /nfs/stak/users/sundaraa/.cache/pip/wheels/f8/c7/3c/7ad569d779e750220d17a44f731411f0ad79b7b123a2e3a02e\n",
      "  Building wheel for networkx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for networkx: filename=networkx-2.2-py2.py3-none-any.whl size=1526923 sha256=c657c14f66d04ca7c9c1178ca5b0d470d5b6536e1b88b2f7cdc29ecafa61034c\n",
      "  Stored in directory: /nfs/stak/users/sundaraa/.cache/pip/wheels/0f/12/87/f2ce9e3aeb87e36bde305edc44e4877932b039491b97f96090\n",
      "  Building wheel for pycollada (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycollada: filename=pycollada-0.6-py3-none-any.whl size=122864 sha256=c2f34dee6c21f9671b5ca18225ea73fc4e63fa9919f08b9530b4b22d50ea08f1\n",
      "  Stored in directory: /nfs/stak/users/sundaraa/.cache/pip/wheels/1c/c9/80/1a8237608423f9adda559b0fc6d97796909b5aa72149524040\n",
      "  Building wheel for PyOpenGL (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyOpenGL: filename=PyOpenGL-3.1.0-py3-none-any.whl size=1745210 sha256=a4dd65512481375cc60eb8abf25416a56e882a21e2ce35d8bbca2c6ccad59a99\n",
      "  Stored in directory: /nfs/stak/users/sundaraa/.cache/pip/wheels/2c/60/a8/75dc000450f1a148c66456347f4bd01a6b60205557b6b5cab7\n",
      "Successfully built gym networkx pycollada PyOpenGL\n",
      "Installing collected packages: trimesh, PyOpenGL, pyglet, networkx, imageio, freetype-py, pyrender, pycollada, lxml, urdfpy, pybullet, gym, urdfenvs\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.26.2\n",
      "    Uninstalling gym-0.26.2:\n",
      "      Successfully uninstalled gym-0.26.2\n",
      "Successfully installed PyOpenGL-3.1.0 freetype-py-2.2.0 gym-0.21.0 imageio-2.15.0 lxml-4.9.1 networkx-2.2 pybullet-3.2.5 pycollada-0.6 pyglet-2.0.0 pyrender-0.1.45 trimesh-3.16.2 urdfenvs-0.4.0 urdfpy-0.0.22\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MotionPlanningEnv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c1eb7e5516ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install urdfenvs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgeneric_urdf_reacher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenericUrdfReacher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/MAS/generic_urdf_reacher.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0murdfenvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murdf_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholonomic_robot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHolonomicRobot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hw1/lib/python3.6/site-packages/urdfenvs/urdf_common/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0murdfenvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murdf_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murdf_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUrdfEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m register(\n\u001b[1;32m      4\u001b[0m     \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'urdf-env-v0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mentry_point\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'urdfenvs.urdf_common:UrdfEnv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hw1/lib/python3.6/site-packages/urdfenvs/urdf_common/urdf_env.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mMotionPlanningEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollisionObstacle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCollisionObstacle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mMotionPlanningGoal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoalComposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoalComposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murdfenvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murdf_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplane\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlane\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MotionPlanningEnv'"
     ]
    }
   ],
   "source": [
    "##import library\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "!pip install gym\n",
    "import gym\n",
    "!pip install tensorboardX\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "!pip install urdfenvs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b60cf2a-3da2-468e-9c6e-0d2e1e42be49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym-legacy-toytext in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (0.0.5)\n",
      "Requirement already satisfied: gym<0.26.0,>=0.19.0 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from gym-legacy-toytext) (0.21.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.1 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from gym<0.26.0,>=0.19.0->gym-legacy-toytext) (4.8.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from gym<0.26.0,>=0.19.0->gym-legacy-toytext) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from gym<0.26.0,>=0.19.0->gym-legacy-toytext) (1.19.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from importlib-metadata>=4.8.1->gym<0.26.0,>=0.19.0->gym-legacy-toytext) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /nfs/stak/users/sundaraa/miniconda3/envs/hw1/lib/python3.6/site-packages (from importlib-metadata>=4.8.1->gym<0.26.0,>=0.19.0->gym-legacy-toytext) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym-legacy-toytext\n",
    "from generic_urdf_reacher import GenericUrdfReacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5209572-68a3-43e0-86e4-c1d4ea882908",
   "metadata": {},
   "outputs": [],
   "source": [
    "##setup env\n",
    "def make_env(render=False):\n",
    "    robots = [\n",
    "        GenericUrdfReacher(urdf=\"loadPointRobot.urdf\", mode=\"vel\"),\n",
    "        GenericUrdfReacher(urdf=\"loadPointRobot.urdf\", mode=\"vel\"),\n",
    "    ]\n",
    "    env = gym.make(\"urdf-env-v0\", dt=0.1, robots=robots, render=render)\n",
    "    # Choosing arbitrary actions\n",
    "    base_pos = np.array(\n",
    "        [\n",
    "            [0.0, 1.0, 0.0],\n",
    "            [0.0, -1.0, 0.0],\n",
    "        ]\n",
    "    )\n",
    "    env.reset(base_pos=base_pos)\n",
    "    env.add_stuff()\n",
    "    ob = env.get_observation()\n",
    "    return env, ob\n",
    "\n",
    "##clear env\n",
    "def kill_env(env):\n",
    "    env.close()\n",
    "    del env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af30cae7-caf6-4176-b586-33682aa3f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplayBuffer():\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28581072-febc-4a9a-b5d9-82de693a7038",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Neural Network Architecture\n",
    "class NN(nn.Module):\n",
    "    def __init__(self,inp,output):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(inp, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.tanh(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ac9a576-8db7-4ce4-8ba2-71a8f067e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dqn(nn.Module):\n",
    "    def __init__(self, n_states, n_actions):\n",
    "        super(Dqn, self).__init__()\n",
    "        self.n_states = n_states\n",
    "        self.n_actions = n_actions\n",
    "        self.eval_net_1 = NN(n_states,n_actions)\n",
    "        self.target_net_1 = NN(n_states,n_actions)\n",
    "        self.eval_net_2 = NN(n_states,n_actions)\n",
    "        self.target_net_2 = NN(n_states,n_actions)\n",
    "        self.optimizer_1 = torch.optim.RMSprop(self.eval_net_1.parameters(), lr=1e-4, alpha=0.95, eps=0.01) ## 10.24 fix alpha and eps\n",
    "        self.optimizer_2 = torch.optim.RMSprop(self.eval_net_2.parameters(), lr=1e-4, alpha=0.95, eps=0.01)\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "        self.replay_memory_1 = ExperienceReplayBuffer(1000)\n",
    "        self.replay_memory_2 = ExperienceReplayBuffer(1000)\n",
    "        self.steps = 0\n",
    "        self.eval_net_1.cuda()\n",
    "        self.target_net_1.cuda()\n",
    "        self.eval_net_2.cuda()\n",
    "        self.target_net_2.cuda()\n",
    "\n",
    "\n",
    "    def choose_action(self, state, eval_net, epsilon):\n",
    "        if random.random() > epsilon:\n",
    "            state = torch.unsqueeze(torch.FloatTensor(state), 0).cuda()\n",
    "            actions_value = eval_net.forward(state)\n",
    "            action = torch.max(actions_value, 1)[1].data.cpu().numpy()[0]\n",
    "        else:\n",
    "            action = random.randint(0, self.n_actions - 1)\n",
    "        return action\n",
    "\n",
    "    def store_transition_1(self, state, action, reward, next_state, done):\n",
    "        self.replay_memory_1.push(state, action, reward, next_state, done)\n",
    "\n",
    "    def store_transition_2(self, state, action, reward, next_state, done):\n",
    "        self.replay_memory_2.push(state, action, reward, next_state, done)\n",
    "\n",
    "\n",
    "    def learn(self, batch_size):\n",
    "        self.steps += 1\n",
    "        if self.steps % 100 == 0:\n",
    "            self.target_net_1.load_state_dict(self.eval_net_1.state_dict())\n",
    "            self.target_net_2.load_state_dict(self.eval_net_2.state_dict())\n",
    "\n",
    "        self.optimizer_1.zero_grad()\n",
    "        self.optimizer_2.zero_grad()\n",
    "\n",
    "        batch_1 = self.replay_memory_1.sample(batch_size)\n",
    "        batch_state_1, batch_action_1, batch_reward_1, batch_next_state_1, batch_done_1 = zip(*batch_1)\n",
    "        batch_state_1 = torch.stack(batch_state_1).cuda()\n",
    "        batch_action_1 = torch.LongTensor(batch_action_1).cuda()\n",
    "        batch_reward_1 = torch.FloatTensor(batch_reward_1).cuda()\n",
    "        batch_next_state_1 = torch.stack(batch_next_state_1).cuda()\n",
    "        batch_done_1 = torch.FloatTensor(batch_done_1).cuda()\n",
    "        q_eval_1 = self.eval_net_1(batch_state_1).gather(1, batch_action_1.unsqueeze(1)).squeeze(1)\n",
    "        q_next_1 = self.target_net_1(batch_next_state_1).detach()\n",
    "        q_target_1 = batch_reward_1 + 0.99 * q_next_1.max(1)[0] * (1 - batch_done_1)\n",
    "        loss_1 = self.loss_func(q_eval_1, q_target_1)\n",
    "        loss_1.backward()\n",
    "        self.optimizer_1.step()\n",
    "\n",
    "\n",
    "        ######\n",
    "        batch_2 = self.replay_memory_2.sample(batch_size)\n",
    "        batch_state_2, batch_action_2, batch_reward_2, batch_next_state_2, batch_done_2 = zip(*batch_2)\n",
    "        batch_state_2 = torch.stack(batch_state_2).cuda()\n",
    "        batch_action_2 = torch.LongTensor(batch_action_2).cuda()\n",
    "        batch_reward_2 = torch.FloatTensor(batch_reward_2).cuda()\n",
    "        batch_next_state_2 = torch.stack(batch_next_state_2).cuda()\n",
    "        batch_done_2 = torch.FloatTensor(batch_done_2).cuda()\n",
    "        q_eval_2 = self.eval_net_2(batch_state_2).gather(1, batch_action_2.unsqueeze(1)).squeeze(1)\n",
    "        q_next_2 = self.target_net_2(batch_next_state_2).detach()\n",
    "        q_target_2 = batch_reward_2 + 0.99 * q_next_2.max(1)[0] * (1 - batch_done_2)\n",
    "        loss_2 = self.loss_func(q_eval_2, q_target_2)\n",
    "        loss_2.backward()\n",
    "        self.optimizer_2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5211e19f-daf9-4ea4-bcbf-6ba77ffc874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(render=False):\n",
    "    env,_ = make_env(render=render)\n",
    "    has_continuous_action_space = True  # continuous action space; else discrete\n",
    "    state_dim = env.observation_spaces_ppo().shape[0]\n",
    "\n",
    "    # action space dimension\n",
    "    if has_continuous_action_space:\n",
    "        action_dim = env.action_spaces_ppo().shape[0]\n",
    "    else:\n",
    "        action_dim = env.action_space.n\n",
    "    \n",
    "    dqn = Dqn(state_dim,action_dim)\n",
    "    writer = SummaryWriter('MAS/runs/dqn')\n",
    "    reward = 0\n",
    "\n",
    "    for i_episode in tqdm(range(1)):\n",
    "        kill_env(env)\n",
    "        #set up env\n",
    "        grid, goals = make_env()\n",
    "        # initialize grid start agent at random position\n",
    "        agent_pos_1 = (random.randint(0, 4), random.randint(0, 9))\n",
    "        agent_pos_2 = (random.randint(0, 4), random.randint(0, 9))\n",
    "        # neighbours = getNeighbours(agent_pos_1[0], agent_pos_1[1], grid.desc)\n",
    "        # if len(neighbours) < 4:\n",
    "        #     neighbours += [0] * (4 - len(neighbours))\n",
    "        neighbours = []\n",
    "        state_1 = list(agent_pos_1) + list(agent_pos_2) + neighbours\n",
    "\n",
    "        state_1 = torch.FloatTensor(state_1)\n",
    "\n",
    "        # neighbours = getNeighbours(agent_pos_2[0], agent_pos_2[1], grid.desc)\n",
    "        # if len(neighbours) < 4:\n",
    "        #     neighbours += [0] * (4 - len(neighbours))\n",
    "\n",
    "        state_2 = list(agent_pos_1) + list(agent_pos_2) + neighbours\n",
    "\n",
    "        state_2 = torch.FloatTensor(state_2)\n",
    "        for t in range(100):\n",
    "            action_1 = dqn.choose_action(state_1, dqn.eval_net_1, 0.1)\n",
    "            action_2 = dqn.choose_action(state_2, dqn.eval_net_2, 0.1)\n",
    "\n",
    "            agent_positions, rewards, done, goals, neighbours, img = env.step(grid, [action_1, action_2], [agent_pos_1, agent_pos_2],  goals)\n",
    "            # next_state_1 = list(agent_positions[0]) + list(agent_positions[1]) + neighbours[:4]\n",
    "            # next_state_2 = list(agent_positions[0]) + list(agent_positions[1]) + neighbours[4:]\n",
    "\n",
    "            next_state_1 = list(agent_positions[0]) + list(agent_positions[1])\n",
    "            next_state_2 = list(agent_positions[0]) + list(agent_positions[1])\n",
    "\n",
    "            reward = rewards[0]+rewards[1]\n",
    "\n",
    "\n",
    "            next_state_1 = torch.FloatTensor(next_state_1)\n",
    "            next_state_2 = torch.FloatTensor(next_state_2)\n",
    "            \n",
    "            #stores val in buffer\n",
    "            dqn.store_transition_1(state_1, action_1, reward, next_state_1, done)\n",
    "            dqn.store_transition_2(state_2, action_2, reward, next_state_2, done)\n",
    "\n",
    "            agent_pos_1 = agent_positions[0]\n",
    "            agent_pos_2 = agent_positions[1]\n",
    "\n",
    "            if dqn.replay_memory_1.__len__() > 50:\n",
    "                dqn.learn(32)\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            state_1 = next_state_1\n",
    "            state_2 = next_state_2\n",
    "        writer.add_scalar('reward_agents', reward, i_episode)\n",
    "    # save model\n",
    "    torch.save(dqn.eval_net_1.state_dict(), 'dqn_a1.pth')\n",
    "    torch.save(dqn.eval_net_2.state_dict(), 'dqn_a2.pth')\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec414e9e-be6d-45c5-ae71-6654cb7e037b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameNotFound",
     "evalue": "Environment urdf-env doesn't exist. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-0ee788d6928a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(render)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhas_continuous_action_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# continuous action space; else discrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstate_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_spaces_ppo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-2674eef98f0e>\u001b[0m in \u001b[0;36mmake_env\u001b[0;34m(render)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mGenericUrdfReacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loadPointRobot.urdf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"vel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     ]\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"urdf-env-v0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrobots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Choosing arbitrary actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     base_pos = np.array(\n",
      "\u001b[0;32m~/miniconda3/envs/hw1/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hw1/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_specs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnvSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hw1/lib/python3.6/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0menv_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoytext_envs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 raise error.UnregisteredEnv(\n\u001b[0;32m--> 198\u001b[0;31m                     \"Toytext environment {} has been moved out of Gym. Install it via `pip install gym-legacy-toytext` and add `import gym_toytext` before using it.\".format(\n\u001b[0m\u001b[1;32m    199\u001b[0m                         \u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                     )\n",
      "\u001b[0;31mNameNotFound\u001b[0m: Environment urdf-env doesn't exist. "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec4ccf8-aa66-49e8-85a7-8942e4e36719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
